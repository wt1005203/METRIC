{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig_dims = figure_size_setting(700)\\nfig_dims = [fig_dims[0], fig_dims[1]*1]\\nfig, axes = plt.subplots(1, 1, figsize=fig_dims, sharex=True)\\n\\naxes.set_xlabel(\"\")\\naxes.set_title(\\'\\')\\n\\nfig.tight_layout()\\n#fig.subplots_adjust(left=.1, bottom=.12, right=.97, top=.93, hspace=0.1)\\n#fig.savefig(\"./figures/XXX.png\", dpi=300)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from scipy.stats import sem\n",
    "import os\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import scipy\n",
    "from scipy.integrate import odeint\n",
    "import scipy.integrate as integ\n",
    "\n",
    "#%% Plot Tong's default setting\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 15\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE, family='sans-serif', serif='Arial')          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('text')\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "my_locator = MaxNLocator(6)\n",
    "\n",
    "color_list = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "def figure_size_setting(WIDTH):\n",
    "    #WIDTH = 700.0  # the number latex spits out\n",
    "    FACTOR = 0.8  # the fraction of the width you'd like the figure to occupy\n",
    "    fig_width_pt  = WIDTH * FACTOR\n",
    "    inches_per_pt = 1.0 / 72.27\n",
    "    golden_ratio  = (np.sqrt(5) - 1.0) / 2.0  # because it looks good\n",
    "    fig_width_in  = fig_width_pt * inches_per_pt  # figure width in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio   # figure height in inches\n",
    "    fig_dims    = [fig_width_in, fig_height_in] # fig dims as a list\n",
    "    return fig_dims\n",
    "\n",
    "'''\n",
    "fig_dims = figure_size_setting(700)\n",
    "fig_dims = [fig_dims[0], fig_dims[1]*1]\n",
    "fig, axes = plt.subplots(1, 1, figsize=fig_dims, sharex=True)\n",
    "\n",
    "axes.set_xlabel(\"\")\n",
    "axes.set_title('')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(left=.1, bottom=.12, right=.97, top=.93, hspace=0.1)\n",
    "#fig.savefig(\"./figures/XXX.png\", dpi=300)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (dietary information and metagenome) from Dan Knights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutrition + microbiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microbiome_ori = pd.read_csv(\"../Data_from_Dan_Knights/microbiome/processed_sample/taxonomy_counts_s.txt\", delimiter='\\t', index_col=0);\n",
    "#df_diet_ori = pd.read_csv(\"../Data_from_Dan_Knights/diet/processed_nutr/nutr_65.txt\", delimiter='\\t', index_col=0);\n",
    "df_diet_ori = pd.read_csv(\"../Data_from_Dan_Knights/diet/nutrition_totals.txt\", delimiter='\\t', index_col=0).iloc[:,4:-1].transpose()\n",
    "#df_diet_ori = pd.read_csv(\"../Data_from_Dan_Knights/diet/processed_food/dhydrt.txt\", delimiter='\\t', index_col=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### select common subjects\n",
    "i_intersected_subjects = np.intersect1d(df_diet_ori.columns, df_microbiome_ori.columns);\n",
    "df_microbiome = df_microbiome_ori.loc[:, i_intersected_subjects];\n",
    "df_diet = df_diet_ori.loc[:, i_intersected_subjects];\n",
    "\n",
    "#### select species only\n",
    "i_valid_species = np.where(list(map(lambda x: \"s__\" in x, df_microbiome.index)))[0]\n",
    "df_microbiome = df_microbiome.iloc[i_valid_species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 101) (478, 191)\n"
     ]
    }
   ],
   "source": [
    "from skbio.stats.composition import clr\n",
    "pseudo_count = df_diet.transpose()[df_diet.transpose()>0].min().min() / 10\n",
    "#diet_comp_df = pd.DataFrame(data=np.transpose(clr(df_diet.transpose() + pseudo_count)), \n",
    "#                             index=df_diet.index, columns=df_diet.columns)\n",
    "diet_comp_df = np.log(df_diet.transpose() + pseudo_count).transpose()\n",
    "pseudo_count = df_microbiome.transpose()[df_microbiome.transpose()>0].min().min() / 10\n",
    "micro_comp_df = pd.DataFrame(data=np.transpose(clr(df_microbiome.transpose() + pseudo_count)), \n",
    "                             index=df_microbiome.index, columns=df_microbiome.columns)\n",
    "\n",
    "diet_comp_df = diet_comp_df.transpose()\n",
    "micro_comp_df = micro_comp_df.transpose()\n",
    "\n",
    "print(diet_comp_df.shape, micro_comp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "for noise_level in [0.0, 0.5, 1.0, 1.5, 2.0]:  \n",
    "    noises = np.random.normal(loc=0.0, scale=np.log10(10**noise_level), size=diet_comp_df.values.shape)\n",
    "    X = np.concatenate([micro_comp_df.values, diet_comp_df.values+noises], axis=1)\n",
    "    y = diet_comp_df.values\n",
    "    for i, random_state in enumerate([42,43,44,45,46]):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "        path_prefix = \"./noise_level_\"+str(noise_level)+\"/microbiome_nutrient_split\"+str(i+1)+\"/processed_data/\"\n",
    "        if os.path.exists(\"/\".join(path_prefix.split(\"/\")[:-3]))==False:\n",
    "            os.mkdir(\"/\".join(path_prefix.split(\"/\")[:-3])) \n",
    "        if os.path.exists(\"/\".join(path_prefix.split(\"/\")[:-2]))==False:\n",
    "            os.mkdir(\"/\".join(path_prefix.split(\"/\")[:-2])) \n",
    "        if os.path.exists(path_prefix)==False:\n",
    "            os.mkdir(path_prefix) \n",
    "        np.savetxt(path_prefix + \"X_train.csv\", X_train, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"y_train.csv\", y_train, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"X_test.csv\", X_test, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"y_test.csv\", y_test, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"compound_names.csv\", diet_comp_df.columns, delimiter='\\t', fmt = '%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for noise_level in [0.5, 1.0, 2.0]:  \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=5, random_state=42)\n",
    "    noises = np.random.normal(loc=0.0, scale=np.log10(10**noise_level), size=diet_comp_df.values.shape)\n",
    "    X = np.concatenate([micro_comp_df.values, diet_comp_df.values+noises], axis=1)\n",
    "    y = diet_comp_df.values\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test, y_train, y_test = X[train_index,:], X[test_index,:], y[train_index,:], y[test_index,:]\n",
    "\n",
    "        path_prefix = \"./noise_level_\"+str(noise_level)+\"/microbiome_nutrient_split\"+str(i+1)+\"/processed_data/\"\n",
    "        if os.path.exists(\"/\".join(path_prefix.split(\"/\")[:-3]))==False:\n",
    "            os.mkdir(\"/\".join(path_prefix.split(\"/\")[:-3])) \n",
    "        if os.path.exists(\"/\".join(path_prefix.split(\"/\")[:-2]))==False:\n",
    "            os.mkdir(\"/\".join(path_prefix.split(\"/\")[:-2])) \n",
    "        if os.path.exists(path_prefix)==False:\n",
    "            os.mkdir(path_prefix) \n",
    "        np.savetxt(path_prefix + \"X_train.csv\", X_train, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"y_train.csv\", y_train, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"X_test.csv\", X_test, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"y_test.csv\", y_test, delimiter=',')\n",
    "        np.savetxt(path_prefix + \"compound_names.csv\", diet_comp_df.columns, delimiter='\\t', fmt = '%s')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROT', 'TFAT', 'CARB', 'MOIS', 'ALC', 'CAFF', 'THEO', 'SUGR', 'FIBE',\n",
       "       'CALC',\n",
       "       ...\n",
       "       'PF_NUTSDS', 'PF_LEGUMES', 'D_TOTAL', 'D_MILK', 'D_YOGURT', 'D_CHEESE',\n",
       "       'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet_comp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
